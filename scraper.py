#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import csv
import time
import re
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# --- –ö–û–ù–§–ò–ì ---
BASE_URL   = "https://brawlify.com/ru/brawlers"
LIST_URL   = f"{BASE_URL}/rarity"
OUTPUT_CSV = "data/brawlers.csv"
# ----------------

def slugify(name: str) -> str:
    """
    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∏–º—è –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ –≤ slug –¥–ª—è URL.
    –ù–∞–ø—Ä–∏–º–µ—Ä: "8-Bit" ‚Üí "8-bit", —É–±–∏—Ä–∞–µ—Ç –∞–ø–æ—Å—Ç—Ä–æ—Ñ—ã.
    """
    s = name.lower().replace(" ", "-")
    return re.sub(r"[‚Äô'‚Ä≥‚Äú]", "", s)

def scrape():
    # --- 1. –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º Headless Chrome —Å –Ω—É–∂–Ω—ã–º–∏ —Ñ–ª–∞–≥–∞–º–∏ ---
    chrome_options = webdriver.ChromeOptions()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--disable-extensions")
    # –£–∫–∞–∂–∏—Ç–µ, –µ—Å–ª–∏ –≤–∞—à chrome —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –Ω–µ –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º –º–µ—Å—Ç–µ:
    chrome_options.binary_location = "/usr/bin/google-chrome"
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=chrome_options)

    # --- 2. –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å–æ —Å–ø–∏—Å–∫–æ–º –±–æ–π—Ü–æ–≤ –ø–æ —Ä–µ–¥–∫–æ—Å—Ç–∏ ---
    print("üì• –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ø–∏—Å–æ–∫ –±–æ–π—Ü–æ–≤‚Ä¶")
    driver.get(LIST_URL)

    # –î–æ–∂–¥—ë–º—Å—è –ø–æ—è–≤–ª–µ–Ω–∏—è –∫–∞—Ä—Ç–æ—á–µ–∫ (JS-—Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥)
    try:
        WebDriverWait(driver, 15).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "div.row div.card"))
        )
    except Exception as e:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–∂–¥–∞—Ç—å—Å—è –∫–∞—Ä—Ç–æ—á–µ–∫:", e)
        driver.quit()
        return

    # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —Å—Å—ã–ª–∫–∏ –≤–Ω—É—Ç—Ä–∏ –∫–∞—Ä—Ç–æ—á–µ–∫
    cards = driver.find_elements(By.CSS_SELECTOR, "div.row div.card a[href*='/brawlers/']")
    brawlers = []
    for a in cards:
        href = a.get_attribute("href")
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ —Å–∞–º—É —Å—Ç—Ä–∞–Ω–∏—Ü—É /rarity
        if href.endswith("/rarity"):
            continue
        # –ò–º—è –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ –±–µ—Ä—ë–º –∏–∑ –∞—Ç—Ä–∏–±—É—Ç–∞ alt —É –∫–∞—Ä—Ç–∏–Ω–∫–∏
        try:
            img = a.find_element(By.TAG_NAME, "img")
            name = img.get_attribute("alt").strip()
        except:
            # –ï—Å–ª–∏ –Ω–µ—Ç –∫–∞—Ä—Ç–∏–Ω–∫–∏, –±–µ—Ä—ë–º —Ç–µ–∫—Å—Ç —Å—Å—ã–ª–∫–∏
            name = a.text.strip()
        brawlers.append((name, href))
    print(f"   –ù–∞–π–¥–µ–Ω–æ {len(brawlers)} –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π.")

    # --- 3. –ü–∞—Ä—Å–∏–º —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å–æ —Å—Ç–∞—Ç–∞–º–∏ –∫–∞–∂–¥–æ–≥–æ –±–æ–π—Ü–∞ ---
    rows = []
    for name, url in brawlers:
        print(f"‚è≥ –ü–∞—Ä—Å–∏–º {name} ‚Äî {url}")
        driver.get(url)
        # –ñ–¥—ë–º, –ø–æ–∫–∞ —Ç–∞–±–ª–∏—Ü–∞ —Å–æ —Å—Ç–∞—Ç–∞–º–∏ –ø–æ—è–≤–∏—Ç—Å—è
        try:
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "table.table-striped"))
            )
        except:
            print(f"   ‚ö†Ô∏è –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è {name} –Ω–µ –Ω–∞—à–ª–∞—Å—å, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º.")
            continue

        soup = BeautifulSoup(driver.page_source, "lxml")
        table = soup.select_one("table.table-striped")
        stats = {"Name": name}
        for tr in table.find_all("tr"):
            cols = tr.find_all(["th","td"])
            if len(cols) >= 2:
                key = cols[0].get_text(strip=True).rstrip(":")
                val = cols[1].get_text(strip=True)
                stats[key] = val
        rows.append(stats)
        time.sleep(0.3)  # —á—Ç–æ–±—ã –Ω–µ —à—Ç—É—Ä–º–æ–≤–∞—Ç—å —Å–∞–π—Ç

    driver.quit()

    if not rows:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–π –∑–∞–ø–∏—Å–∏.")
        return

    # --- 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ CSV ---
    fields = list(rows[0].keys())
    print(f"üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º {len(rows)} –∑–∞–ø–∏—Å–µ–π –≤ {OUTPUT_CSV}‚Ä¶")
    with open(OUTPUT_CSV, "w", encoding="utf-8", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=fields)
        writer.writeheader()
        writer.writerows(rows)
    print("‚úÖ –ì–æ—Ç–æ–≤–æ! –û—Ç–∫—Ä–æ–π—Ç–µ —Ñ–∞–π–ª data/brawlers.csv")

if __name__ == "__main__":
    scrape()
